{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fnn import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the output of a single Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " __Layer 0__<br>\n",
    "input size = 2<br>\n",
    "output size = 1<br>\n",
    "input = [2,3] <br>\n",
    "Weights = [0 1]<br>\n",
    "Bias = 4<br>\n",
    "Activation Function = Sigmoid<br>\n",
    "expected out = sigmoid(7) = 0.999088948806<br>\n",
    "\n",
    "Final output = 0.999088948806"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[0 1]\n",
      "4\n",
      "0.999088948806\n",
      "0.999088948806\n"
     ]
    }
   ],
   "source": [
    "l = Layers(2,1,0)\n",
    "w = np.array([0,1])\n",
    "b = 4\n",
    "x = np.array([2,3])\n",
    "l.setWeight(w)\n",
    "l.setBias(b)\n",
    "print(w.T @ x)\n",
    "print(l.Weights)\n",
    "print(l.bias)\n",
    "print(l.evaluate(x,sigmoid))\n",
    "print(sigmoid(7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the output of a 2-Layer FNN\n",
    "Activation Function = Sigmoid <br>\n",
    "__Layer 0__<br>\n",
    "input size = 2<br>\n",
    "output size = 2<br>\n",
    "input = [2,3]<br>\n",
    "weight = [[0,1],[1,0]]<br>\n",
    "bias = [4,0]<br>\n",
    "z = sigmoid([7,2])<br>\n",
    "<br>\n",
    "__Layer 1__ <br>\n",
    "input size = 2<br>\n",
    "output size = 1<br>\n",
    "input = sigmoid([7,2])<br>\n",
    "weight = [0,1]<br>\n",
    "bias = 0<br>\n",
    "expected = sigmoid(sigmoid(2)) = 0.706987368<br>\n",
    "\n",
    "Final output = 0.706987368<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.706987368\n",
      "0.706987368\n"
     ]
    }
   ],
   "source": [
    "input_size = 2\n",
    "x = np.array([2,3])\n",
    "w_1 = np.array([[0,1],[1,0]])\n",
    "b_1 = np.array([4,0])\n",
    "w_2 = np.array([0,1])\n",
    "b_2 = 0\n",
    "test_FNN = FNN(input_size)\n",
    "test_FNN.addLayer(2,2)\n",
    "test_FNN.addLayer(2,1)\n",
    "test_FNN.layer_list[0].setWeight(w_1)\n",
    "test_FNN.layer_list[0].setBias(b_1)\n",
    "test_FNN.layer_list[1].setWeight(w_2)\n",
    "test_FNN.layer_list[1].setBias(b_2)\n",
    "print(sigmoid(sigmoid(2)))\n",
    "print(test_FNN.feed(x,sigmoid))\n",
    "del test_FNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the output of the Quadratic cost function\n",
    "z = [1,0,0,1]<br>\n",
    "z_label = [1,1,0,1]<br>\n",
    "expected = 0.25*((1-1)^2+(1-0)^2+(0-0)^2+(1-1)^2) = 0.25 <25>\n",
    "\n",
    "final output = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from util import *\n",
    "z = np.array([1,0,0,1])\n",
    "z_label = np.array([1,1,0,1])\n",
    "cost_quadratic(z,z_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = np.array([[-2,-1],[25,6],[17,4],[-15,-6]])\n",
    "y = np.array([1,0,0,1])\n",
    "alpha = 0.1\n",
    "FNN_2 = FNN(2)\n",
    "FNN_2.addLayer(2,2)\n",
    "FNN_2.addLayer(2,1)\n",
    "cost = FNN_2.train(alpha,x,y,dc_dz = dquadratic_dz,batches = 4)\n",
    "FNN_2.feed(np.array([-8,2]),sigmoid)\n",
    "plt.plot(np.arange(len(cost)),cost)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the the results of back propagation argee with the finite difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Back propagation\n",
    "def back_propagation(fnn,x,y):\n",
    "    fnn.feed(x,sigmoid)\n",
    "    delta_list = {}\n",
    "    weights_gradients = []\n",
    "    bias_gradients = []\n",
    "    for i in range(len(fnn.layer_list)-1,-1,-1):\n",
    "        if i == len(fnn.layer_list)-1:\n",
    "            delta = dquadratic_dz(fnn.layer_list[i].z,y) @ d_sigmoid(fnn.layer_list[i].y)\n",
    "            delta_list[i] = delta\n",
    "        else:\n",
    "            delta = (delta_list[i+1] * fnn.layer_list[i+1].Weights.T) @ d_sigmoid(fnn.layer_list[i].y)\n",
    "            delta_list[i] = delta\n",
    "        weights_gradient = np.outer(fnn.layer_list[i].x,delta)\n",
    "        bias_gradient = delta\n",
    "        weights_gradients.append(weights_gradient)\n",
    "        bias_gradients.append(float(bias_gradient))\n",
    "    return weights_gradients,bias_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fnn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'Ising/'\n",
    "file = open(url+'train_data.txt').readlines()\n",
    "train_dataset = np.zeros([10000,100])\n",
    "i = 0 \n",
    "for line in file:\n",
    "    line = line.split()\n",
    "    for j in range(len(line)):\n",
    "        train_dataset[i][j] = int(line[j])\n",
    "    i+=1\n",
    "file = open(url+'train_label.txt').readlines()\n",
    "train_labelset = np.zeros([10000,1])\n",
    "i = 0\n",
    "for line in file:\n",
    "    line = line.split()\n",
    "    for j in range(len(line)):\n",
    "        train_labelset[i][j] = int(line[j])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ising_FNN = FNN(100)\n",
    "Ising_FNN.addLayer(100,100)\n",
    "Ising_FNN.addLayer(100,1)\n",
    "w = np.zeros([100,1])\n",
    "for i in range(len(w)):\n",
    "    w[i] = np.random.uniform(-0.01,0.01)\n",
    "Ising_FNN.layer_list[0].setWeight(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ising_FNN.train(alpha,train_dataset,train_labelset,dc_dz = dquadratic_dz , batches = 100,epoches = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'Ising/'\n",
    "file = open(url+'test_data.txt').readlines()\n",
    "test_dataset = np.zeros([10000,100])\n",
    "i = 0 \n",
    "for line in file:\n",
    "    line = line.split()\n",
    "    for j in range(len(line)):\n",
    "        test_dataset[i][j] = int(line[j])\n",
    "    i+=1\n",
    "file = open(url+'test_label.txt').readlines()\n",
    "test_labelset = np.zeros([10000,1])\n",
    "i = 0\n",
    "for line in file:\n",
    "    line = line.split()\n",
    "    for j in range(len(line)):\n",
    "        test_labelset[i][j] = int(line[j])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'match': 9023, 'fail': 977})\n",
      "0.9023\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "accuracy = collections.Counter()\n",
    "accuracy['match'] = 0\n",
    "accuracy['fail'] = 0\n",
    "predict_z = []\n",
    "for  test_data,test_label in zip(test_dataset,test_labelset):\n",
    "    predict = Ising_FNN.predict(test_data,sigmoid)\n",
    "    predict_z.append(predict)\n",
    "    if(abs(test_label-predict) < 0.5):\n",
    "        accuracy['match'] += 1\n",
    "    else:\n",
    "        accuracy['fail'] += 1\n",
    "\n",
    "print(accuracy)\n",
    "print(accuracy['match']/len(test_dataset))\n",
    "print(len(predict_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = open(url+'test_betaJ.txt').readlines()\n",
    "test_betaJ = []\n",
    "i = 0\n",
    "for line in file:\n",
    "    line = line.split()\n",
    "    for j in range(len(line)):\n",
    "        test_betaJ.append(float(line[j]))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEtZJREFUeJzt3X9sXWd9x/H3Fzfd7hjgiQSJOAnJ\ntmCWEaQwryBV2thgctppbVYYaiW0MXVEmyibBLKWCMRQ+SMFS6BN6350G+KHBKVDkZWpYd5Gi9DQ\niurOpVmKjEJha5xphB9m0zA0zb77wzftjevknuv74/g+fr8kS/c89zn3fJ9c+3NPnnPOPZGZSJLK\n8ry6C5Ak9Z7hLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSrQNXVteOvWrbl79+66\nNi9JQ+mRRx75VmZua9evtnDfvXs3c3NzdW1ekoZSRPx7lX5Oy0hSgQx3SSqQ4S5JBTLcJalAbcM9\nIj4SEd+MiH+7wvMREX8SEWci4rGIeHXvy5QkdaLKnvtHgYNXef4GYG/z5zDw592XJUnqRttwz8wv\nAN+5SpebgY/nioeA0Yh4aa8KlCR1rhdz7mPAky3LZ5ttkqSaDPQipog4zMrUDbt27RrkpiUNqZn5\nRaZnFzi3tMz20QZTk+McOlBt/7Gbdevedrd6Ee6LwM6W5R3NtufIzHuAewAmJia8M7e0CXQbkEeP\nn2L5wkUAFpeWOXr8FEDb1+hm3bq33Qu9mJY5Afxm86yZ1wLfy8z/7MHrStoAZuYXuf6uB9hz5H6u\nv+sBZubX3He74rpHj59icWmZ5NmQq/oa07MLzwTkJcsXLjI9u9DXdevedi+03XOPiE8BrwO2RsRZ\n4I+ALQCZ+RfASeBG4AzwfeC3+1WspMHqdg/0aiFXZf1zS8sdtfdq3bq33Qttwz0zb2vzfAJv71lF\nknpuvVMjdYYzwPbRBotr9N0+2ujrunVvuxe8QlUqXDdTI70I507aV5uaHKexZeSytsaWEaYmx/u6\nbt3b7gXDXSpcN/O/dYYzrEz9HLtlP2OjDQIYG21w7Jb9lf7X0M26dW+7F2JlVmXwJiYm0u9zl/pv\nz5H7WeuvPICv3/WrV1139Zw7rIRzJ0FV9ymBpYmIRzJzol2/2m7WIWkwupn/vRTC3YTzoQNjhnkN\nDHepcFOT42vufXcyNWI4Dx/DXSpcL/a+NXwMd2kTcO978/FsGUkqkOEuSQUy3CWpQIa7JBXIcJek\nAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ\n4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoEqhXtEHIyIhYg4ExFH1nh+V0Q8GBHzEfFY\nRNzY+1IlSVW1DfeIGAHuBm4A9gG3RcS+Vd3eA9yXmQeAW4E/63WhkqTqquy5XwecycwnMvMp4F7g\n5lV9Enhh8/GLgHO9K1GS1KlrKvQZA55sWT4LvGZVn/cB/xAR7wCeD7yhJ9VJktalVwdUbwM+mpk7\ngBuBT0TEc147Ig5HxFxEzJ0/f75Hm5YkrVYl3BeBnS3LO5ptrW4H7gPIzH8BfhTYuvqFMvOezJzI\nzIlt27atr2JJUltVwv1hYG9E7ImIa1k5YHpiVZ//AF4PEBE/w0q4u2suSTVpG+6Z+TRwBzALfIWV\ns2JOR8SdEXFTs9u7gLdFxJeBTwFvzczsV9GSpKurckCVzDwJnFzV9t6Wx48D1/e2NEnSenmFqiQV\nyHCXpAIZ7pJUIMNdkgpkuEtSgSqdLSOpezPzi0zPLnBuaZntow2mJsc5dGCs7rJUKMNdGoCZ+UWO\nHj/F8oWLACwuLXP0+CmASgHvB4M65bSMNADTswvPBPslyxcuMj270HbdSx8Mi0vLJM9+MMzMr/4W\nEOlZhrs0AOeWljtqb9XNB4M2L8NdGoDto42O2lt188GgzctwlwZganKcxpaRy9oaW0aYmhxvu243\nHwzavAx3aQAOHRjj2C37GRttEMDYaINjt+yvdFC0mw8GbV6eLSMNyKEDY+s6w+XSOp4to04Y7tIQ\nWO8HgzYvp2UkqUCGuyQVyGkZqSKvEtUwMdylCrr9+gBp0JyWkSrwKlENG8NdqsCrRDVsDHepAq8S\n1bAx3KUKvEpUw8YDqlIFXiWqYWO4SxV5laiGidMyklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCG\nuyQVqFK4R8TBiFiIiDMRceQKfd4cEY9HxOmI+GRvy5QkdaLtRUwRMQLcDfwKcBZ4OCJOZObjLX32\nAkeB6zPzuxHxkn4VLElqr8qe+3XAmcx8IjOfAu4Fbl7V523A3Zn5XYDM/GZvy5QkdaJKuI8BT7Ys\nn222tXo58PKI+GJEPBQRB3tVoCSpc736bplrgL3A64AdwBciYn9mLrV2iojDwGGAXbt29WjTkqTV\nquy5LwI7W5Z3NNtanQVOZOaFzPw68FVWwv4ymXlPZk5k5sS2bdvWW7MkqY0q4f4wsDci9kTEtcCt\nwIlVfWZY2WsnIrayMk3zRA/rlCR1oG24Z+bTwB3ALPAV4L7MPB0Rd0bETc1us8C3I+Jx4EFgKjO/\n3a+iJUlXF5lZy4YnJiZybm6ulm1L0rCKiEcyc6JdP69QlaQCGe6SVCDDXZIKZLhLUoEMd0kqUK+u\nUJWGwsz8ItOzC5xbWmb7aIOpyXEOHVj9bRrS8DPctWnMzC9y9Pgpli9cBGBxaZmjx08BGPAqjtMy\n2jSmZxeeCfZLli9cZHp2oaaKpP4x3LVpnFta7qhdGmaGuzaN7aONjtqlYWa4a9OYmhynsWXksrbG\nlhGmJsdrqkjqHw+oatO4dNDUs2W0GRju2lQOHRgzzLUpOC0jSQUy3CWpQIa7JBXIcJekAhnuklQg\nw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBTLc\nJalAlcI9Ig5GxEJEnImII1fp98aIyIiY6F2JkqROtQ33iBgB7gZuAPYBt0XEvjX6vQD4A+BLvS5S\nktSZKnvu1wFnMvOJzHwKuBe4eY1+7wc+APygh/VJktahSriPAU+2LJ9ttj0jIl4N7MzM+3tYmyRp\nnbo+oBoRzwM+BLyrQt/DETEXEXPnz5/vdtOSpCuoEu6LwM6W5R3NtkteALwS+HxEfAN4LXBirYOq\nmXlPZk5k5sS2bdvWX7Uk6aqqhPvDwN6I2BMR1wK3AicuPZmZ38vMrZm5OzN3Aw8BN2XmXF8qliS1\n1TbcM/Np4A5gFvgKcF9mno6IOyPipn4XKEnq3DVVOmXmSeDkqrb3XqHv67ovS5LUDa9QlaQCGe6S\nVCDDXZIKZLhLUoEqHVCVNoqZ+UWmZxc4t7TM9tEGU5PjHDow1n5FaZMx3DU0ZuYXOXr8FMsXLgKw\nuLTM0eOnAAx4aRWnZTQ0pmcXngn2S5YvXGR6dqGmiqSNy3DX0Di3tNxRu7SZGe4aGttHGx21S5uZ\n4a6hMTU5TmPLyGVtjS0jTE2O11SRtHF5QFVD49JBU8+Wkdoz3DVUDh0YM8ylCpyWkaQCGe6SVCDD\nXZIKZLhLUoEMd0kqkOEuSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwl\nqUB+n7sGbmZ+0RtuSH1muGugZuYXOXr8FMsXLgKwuLTM0eOnAAx4qYecltFATc8uPBPslyxfuMj0\n7EJNFUllMtw1UOeWljtql7Q+lcI9Ig5GxEJEnImII2s8/86IeDwiHouIz0XEy3pfqkqwfbTRUbuk\n9Wkb7hExAtwN3ADsA26LiH2rus0DE5n5KuAzwAd7XajKMDU5TmPLyGVtjS0jTE2O11SRVKYqe+7X\nAWcy84nMfAq4F7i5tUNmPpiZ328uPgTs6G2ZKsWhA2Mcu2U/Y6MNAhgbbXDslv0eTJV6rMrZMmPA\nky3LZ4HXXKX/7cBnuylKZTt0YMwwl/qsp6dCRsRbgAngF6/w/GHgMMCuXbt6uWlJUosq0zKLwM6W\n5R3NtstExBuAdwM3ZeYP13qhzLwnMycyc2Lbtm3rqVeSVEGVcH8Y2BsReyLiWuBW4ERrh4g4APwl\nK8H+zd6XKUnqRNtwz8yngTuAWeArwH2ZeToi7oyIm5rdpoEfB/42Ih6NiBNXeDlJ0gBUmnPPzJPA\nyVVt7215/IYe1yVJ6oJXqEpSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoEM\nd0kqkOEuSQUy3CWpQD29WYc2h5n5RaZnFzi3tMz20QZTk+PeWUnaYAx3dWRmfpGjx0+xfOEiAItL\nyxw9fgrAgJc2EKdl1JHp2YVngv2S5QsXmZ5dqKkiSWtxz30T6mZa5dzSckftkurhnvsmc2laZXFp\nmeTZaZWZ+efcFndN20cbHbVLqofhPqRm5he5/q4H2HPkfq6/64HK4dzttMrU5DiNLSOXtTW2jDA1\nOV6tcEkD4bTMEOrmoGa30yqXXt+zZaSNzXAfQlfb+24XsttHGyyuEeSdTKscOjBmmEsbnNMyQ6ib\nvW+nVaTNwXAfQt0c1Dx0YIxjt+xnbLRBAGOjDY7dst89cakwTsvUpJvTEacmxy+bc4fO9r6dVpHK\nt6nDvdvL6Ne7frdXeXpQU1I7kZm1bHhiYiLn5uZq2TY8N2BhZe+36hRFN+tff9cDax7UHBtt8MUj\nv9zBKCRtNhHxSGZOtOu3aefcuz3fu5v1vcpTUr9t2nDvNmC7Wd+rPCX129CH+3qv1Ow2YLtZ39MR\nJfXbUId7N9+T0m3AdrO+pyNK6rehPlummys1uz3jpBfrG+aS+mWow70X35PSTcAa0JI2qkrTMhFx\nMCIWIuJMRBxZ4/kfiYhPN5//UkTs7nWha/HApCStrW24R8QIcDdwA7APuC0i9q3qdjvw3cz8aeDD\nwAd6XehaPDApSWursud+HXAmM5/IzKeAe4GbV/W5GfhY8/FngNdHRPSuzLV5YFKS1lZlzn0MeLJl\n+Szwmiv1ycynI+J7wIuBb/WiyKtx3luSnmugp0JGxOGImIuIufPnzw9y05K0qVQJ90VgZ8vyjmbb\nmn0i4hrgRcC3V79QZt6TmROZObFt27b1VSxJaqtKuD8M7I2IPRFxLXArcGJVnxPAbzUfvwl4IOv6\nRjJJUvs59+Yc+h3ALDACfCQzT0fEncBcZp4A/gb4REScAb7DygeAJKkmlS5iysyTwMlVbe9tefwD\n4Dd6W5okab2G+rtlJElrM9wlqUCGuyQVqLbb7EXE/wDVbnu0cW1lABdq9Zlj2DhKGIdj6L+XZWbb\nc8nr/FbIhSr3AdzIImLOMdSvhDFAGeNwDBuH0zKSVCDDXZIKVGe431PjtnvFMWwMJYwByhiHY9gg\najugKknqH6dlJKlAfQ33Crfn+4WI+NeIeDoi3tTPWrpRYRzvjIjHI+KxiPhcRLysjjqvpsIYfjci\nTkXEoxHxz2vcbat27cbQ0u+NEZERseHOeKjwPrw1Is4334dHI+J36qiznSrvRUS8ufl3cToiPjno\nGtup8F58uOV9+GpELNVR57plZl9+WPmSsa8BPwlcC3wZ2Leqz27gVcDHgTf1q5YBjOOXgB9rPv49\n4NN1172OMbyw5fFNwN/XXXenY2j2ewHwBeAhYKLuutfxPrwV+NO6a+3BOPYC88BPNJdfUnfd6/l9\naun/Dla+NLH22qv+9HPPve3t+TLzG5n5GPB/fayjW1XG8WBmfr+5+BAr33m/kVQZw3+3LD4f2GgH\nY6rc7hHg/azcw/cHgyyuoqpj2OiqjONtwN2Z+V2AzPzmgGtsp9P34jbgUwOprEf6Ge5r3Z5vGO+H\n1+k4bgc+29eKOldpDBHx9oj4GvBB4PcHVFtVbccQEa8Gdmbm/YMsrANVf5fe2Jzi+0xE7Fzj+bpV\nGcfLgZdHxBcj4qGIODiw6qqp/HfdnGbdAzwwgLp6xgOqPRQRbwEmgOm6a1mPzLw7M38K+EPgPXXX\n04mIeB7wIeBdddfSpb8Ddmfmq4B/5Nkbzw+ba1iZmnkdK3u9fxURo7VWtH63Ap/JzIt1F9KJfoZ7\nldvzDYNK44iINwDvBm7KzB8OqLaqOn0v7gUO9bWizrUbwwuAVwKfj4hvAK8FTmywg6pt34fM/HbL\n789fAz83oNo6UeX36SxwIjMvZObXga+yEvYbRSd/E7cyZFMyQF8PqF4DPMHKf2cuHbD42Sv0/Sgb\n94Bq23EAB1g5OLO37nq7GMPelse/xspdtmqvfT2/T83+n2fjHVCt8j68tOXxrwMP1V33OsdxEPhY\n8/FWVqZAXlx37Z3+PgGvAL5B85qgYfrp9z/gjax8Yn8NeHez7U5W9m4Bfp6VT/j/ZeWG2qfr/gdZ\n5zj+Cfgv4NHmz4m6a17HGP4YON2s/8GrBedGHcOqvhsu3Cu+D8ea78OXm+/DK+queZ3jCFamyR4H\nTgG31l3zen6fgPcBd9Vd63p+vEJVkgrkAVVJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpk\nuEtSgf4f/dws46cPMBIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "mapping = {}\n",
    "print(len(test_betaJ))\n",
    "for betaJ,predict in zip(list(test_betaJ),list(predict_z)):\n",
    "    if betaJ not in mapping:\n",
    "        mapping[betaJ] = [float(predict)]\n",
    "    mapping[betaJ].append(float(predict))\n",
    "avg = []\n",
    "for betaJ in mapping.keys():\n",
    "    avg.append(statistics.mean(mapping[betaJ]))\n",
    "plt.scatter(mapping.keys(),avg) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def quadratic(z,answer):\n",
    "    return (answer-z)**2\n",
    "def c_w(layer,w):\n",
    "    return quadratic(sigmoid(w.T @ layer.x + layer.bias),1)\n",
    "def c_b(layer,b):\n",
    "    return quadratic(sigmoid(layer.Weights.T @ layer.x + b),1)\n",
    "def finite_diff(fnn,x):\n",
    "    fnn.feed(x,sigmoid)\n",
    "    weights_gradients = []\n",
    "    bias_gradients = []\n",
    "    for i in range(len(fnn.layer_list)-1,-1,-1):\n",
    "        weights_gradient = num_diff(fnn.layer_list[i],fnn.layer_list[i].Weights,c_w)\n",
    "        bias_gradient = num_diff(fnn.layer_list[i],fnn.layer_list[i].bias,c_b)\n",
    "        weights_gradients.append(weights_gradient)\n",
    "        bias_gradients.append(bias_gradient)\n",
    "    return weights_gradients,bias_gradients\n",
    "def num_diff(layer,x,f):\n",
    "    return (f(layer,x+0.0001)-f(layer,x))/0.0001\n",
    "def back_propagation(fnn,x,y):\n",
    "    fnn.feed(x,sigmoid)\n",
    "    delta_list = {}\n",
    "    weights_gradients = []\n",
    "    bias_gradients = []\n",
    "    for i in range(len(fnn.layer_list)-1,-1,-1):\n",
    "        if i == len(fnn.layer_list)-1:\n",
    "            delta = dquadratic_dz(fnn.layer_list[i].z,y) @ d_sigmoid(fnn.layer_list[i].y)\n",
    "            delta_list[i] = delta\n",
    "        else:\n",
    "            delta = (delta_list[i+1] * fnn.layer_list[i+1].Weights.T) @ d_sigmoid(fnn.layer_list[i].y)\n",
    "            delta_list[i] = delta\n",
    "        weights_gradient = delta * fnn.layer_list[i].x\n",
    "        bias_gradient = delta\n",
    "        weights_gradients.append(weights_gradient)\n",
    "        bias_gradients.append(float(bias_gradient))\n",
    "    return weights_gradients,bias_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:[ 0.5079451  -0.58552575]\n",
      "w_1:[[-0.54305485]\n",
      " [-0.53274412]]\n",
      "w_2:[[ 1.26133022]\n",
      " [-0.70733292]]\n",
      "b_1:[-0.69603728 -0.78960725]\n",
      "b_2:2\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randn(2)\n",
    "y = 1\n",
    "w_1 = np.random.randn(2,1)\n",
    "w_2 = np.random.randn(2,1)\n",
    "b_1 = np.random.randn(2)\n",
    "b_2 = 2\n",
    "print('x:{}'.format(x))\n",
    "print('w_1:{}'.format(w_1))\n",
    "print('w_2:{}'.format(w_2))\n",
    "print('b_1:{}'.format(b_1))\n",
    "print('b_2:{}'.format(b_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00369505071922\n",
      "[array([-0.00369505])]\n",
      "[-0.0038691980052152014]\n"
     ]
    }
   ],
   "source": [
    "from util import *\n",
    "fnn_test = FNN(2)\n",
    "fnn_test.addLayer(2,1)\n",
    "#fnn_test.addLayer(2,1)\n",
    "fnn_test.layer_list[0].setWeight(w_2)\n",
    "fnn_test.layer_list[0].setBias(b_2)\n",
    "#fnn_test.layer_list[1].setWeight(w_2)\n",
    "#fnn_test.layer_list[1].setBias(b_2)\n",
    "weights_g,bias_g = back_propagation(fnn_test,x,y)\n",
    "print(np.linalg.norm(weights_g[0]))\n",
    "print(weights_g)\n",
    "print(bias_g)\n",
    "del fnn_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0.00030018])]\n",
      "[array([-0.00386884])]\n"
     ]
    }
   ],
   "source": [
    "from util import *\n",
    "fnn_test = FNN(2)\n",
    "fnn_test.addLayer(2,1)\n",
    "#fnn_test.addLayer(2,1)\n",
    "fnn_test.layer_list[0].setWeight(w_2)\n",
    "fnn_test.layer_list[0].setBias(b_2)\n",
    "#fnn_test.layer_list[1].setWeight(w_2)\n",
    "#fnn_test.layer_list[1].setBias(b_2)\n",
    "weights_g,bias_g = finite_diff(fnn_test,x)\n",
    "print(weights_g)\n",
    "print(bias_g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.68124297])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Add' object has no attribute 'exp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-250-ceaf0e330265>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mweights_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_diff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfnn_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWeights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mweights_gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-246-0e089ccfd2c3>\u001b[0m in \u001b[0;36mnum_diff\u001b[0;34m(x, f)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mweights_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbias_gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnum_diff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mback_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mfnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-246-0e089ccfd2c3>\u001b[0m in \u001b[0;36mc_w\u001b[0;34m(w)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mc_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mquadratic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mc_b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mquadratic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yukunjin/Desktop/PHYS498/p3/FNN/util.py\u001b[0m in \u001b[0;36msigmoid\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0md_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Add' object has no attribute 'exp'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.76852478,  0.9836975 ])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from util import *\n",
    "l = Layers(2,2,0)\n",
    "w = np.array([[-1,1],[-2,3]],dtype = 'float')\n",
    "b = np.array([2,3])\n",
    "x = np.array([0.2,0.3])\n",
    "y = np.array([0,1])\n",
    "l.setWeight(w)\n",
    "l.setBias(b)\n",
    "l.evaluate(x,sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.27301281, -0.00051781])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(quadratic(sigmoid(w.T @ x + (b+0.01)),y) - quadratic(sigmoid(w.T @x + b),y))/0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.05468635 -0.00010457]\n",
      " [ 0.0820294  -0.00015686]]\n"
     ]
    }
   ],
   "source": [
    "weight_gradient = []\n",
    "for i in range(len(w)):\n",
    "    preturbed_w = w.copy()\n",
    "    preturbed_w[i] += 0.0001\n",
    "    weight_gradient.append((quadratic(sigmoid((preturbed_w.T @ x + b)),y) - quadratic(sigmoid(w.T @ x + b),y))/0.0001)\n",
    "print(np.array(weight_gradient))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.27343257 -0.00052288]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.05468651, -0.00010458],\n",
       "       [ 0.08202977, -0.00015686]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta = dquadratic_dz(l.z,y) * d_sigmoid(l.y)\n",
    "print(delta)\n",
    "np.outer(x,delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def back_propagation(layer,y):\n",
    "    delta = dquadratic_dz(layer.z,y) * d_sigmoid(layer.y)\n",
    "    bias_gradients = delta\n",
    "    weight_gradients = np.outer(layer.x,delta)\n",
    "    return weight_gradients,bias_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
