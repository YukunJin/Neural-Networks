{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fnn import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the output of a single Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " __Layer 0__<br>\n",
    "input size = 2<br>\n",
    "output size = 1<br>\n",
    "input = [2,3] <br>\n",
    "Weights = [0 1]<br>\n",
    "Bias = 4<br>\n",
    "Activation Function = Sigmoid<br>\n",
    "expected out = sigmoid(7) = 0.999088948806<br>\n",
    "\n",
    "Final output = 0.999088948806"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[0 1]\n",
      "4\n",
      "0.999088948806\n",
      "0.999088948806\n"
     ]
    }
   ],
   "source": [
    "l = Layers(2,1,0)\n",
    "w = np.array([0,1])\n",
    "b = 4\n",
    "x = np.array([2,3])\n",
    "l.setWeight(w)\n",
    "l.setBias(b)\n",
    "print(w.T @ x)\n",
    "print(l.Weights)\n",
    "print(l.bias)\n",
    "print(l.evaluate(x,sigmoid))\n",
    "print(sigmoid(7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the output of a 2-Layer FNN\n",
    "Activation Function = Sigmoid <br>\n",
    "__Layer 0__<br>\n",
    "input size = 2<br>\n",
    "output size = 2<br>\n",
    "input = [2,3]<br>\n",
    "weight = [[0,1],[1,0]]<br>\n",
    "bias = [4,0]<br>\n",
    "z = sigmoid([7,2])<br>\n",
    "<br>\n",
    "__Layer 1__ <br>\n",
    "input size = 2<br>\n",
    "output size = 1<br>\n",
    "input = sigmoid([7,2])<br>\n",
    "weight = [0,1]<br>\n",
    "bias = 0<br>\n",
    "expected = sigmoid(sigmoid(2)) = 0.706987368<br>\n",
    "\n",
    "Final output = 0.706987368<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.706987368\n",
      "0.706987368\n"
     ]
    }
   ],
   "source": [
    "input_size = 2\n",
    "x = np.array([2,3])\n",
    "w_1 = np.array([[0,1],[1,0]])\n",
    "b_1 = np.array([4,0])\n",
    "w_2 = np.array([0,1])\n",
    "b_2 = 0\n",
    "test_FNN = FNN(input_size)\n",
    "test_FNN.addLayer(2,2)\n",
    "test_FNN.addLayer(2,1)\n",
    "test_FNN.layer_list[0].setWeight(w_1)\n",
    "test_FNN.layer_list[0].setBias(b_1)\n",
    "test_FNN.layer_list[1].setWeight(w_2)\n",
    "test_FNN.layer_list[1].setBias(b_2)\n",
    "print(sigmoid(sigmoid(2)))\n",
    "print(test_FNN.feed(x,sigmoid))\n",
    "del test_FNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the output of the Quadratic cost function\n",
    "z = [1,0,0,1]<br>\n",
    "z_label = [1,1,0,1]<br>\n",
    "expected = 0.25*((1-1)^2+(1-0)^2+(0-0)^2+(1-1)^2) = 0.25 <25>\n",
    "\n",
    "final output = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from util import *\n",
    "z = np.array([1,0,0,1])\n",
    "z_label = np.array([1,1,0,1])\n",
    "cost_quadratic(z,z_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traninig a simple FNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0.96285619]), array([ 0.96384835]), array([ 0.07647689]), array([ 0.05605059]), array([ 0.96389972])]\n",
      "0.433286131126\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = np.array([[-2,-1],[25,6],[17,4],[-15,-6]])\n",
    "y = np.array([1,0,0,1])\n",
    "alpha = 0.1\n",
    "FNN_2 = FNN(2)\n",
    "FNN_2.addLayer(2,2)\n",
    "FNN_2.addLayer(2,1)\n",
    "FNN_2.train(alpha,x,y,dc_dz = dquadratic_dz,batches = 4)\n",
    "test_set = np.array([[-3,-4],[-6,-1],[2,3],[20,0],[-16,2]])\n",
    "test_z = np.array([1,1,0,0,1])\n",
    "predict = []\n",
    "for x in test_set:\n",
    "    predict.append(FNN_2.predict(x,sigmoid))\n",
    "print(predict)\n",
    "print(cost_quadratic(np.array(predict),test_z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the the results of back propagation argee with the finite difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quadratic(z,answer):\n",
    "    return (answer-z)**2\n",
    "#### Back propagation\n",
    "def back_propagation(fnn,x,y):\n",
    "    fnn.feed(x,sigmoid)\n",
    "    delta_list = {}\n",
    "    weights_gradients = []\n",
    "    bias_gradients = []\n",
    "    for i in range(len(fnn.layer_list)-1,-1,-1):\n",
    "        if i == len(fnn.layer_list)-1:\n",
    "            delta = dquadratic_dz(fnn.layer_list[i].z,y) * d_sigmoid(fnn.layer_list[i].y)\n",
    "            delta_list[i] = delta\n",
    "            #delta = dquadratic_dz(l.z,y) * d_sigmoid(l.y)\n",
    "        else:\n",
    "            print('hh')\n",
    "            delta = (delta_list[i+1] * fnn.layer_list[i+1].Weights.T) @ d_sigmoid(fnn.layer_list[i].y)\n",
    "            delta_list[i] = delta\n",
    "        weights_gradient = np.outer(fnn.layer_list[i].x,delta)\n",
    "        bias_gradient = delta\n",
    "        weights_gradients.append(weights_gradient)\n",
    "        bias_gradients.append(bias_gradient)\n",
    "    return weights_gradients,bias_gradients\n",
    "#### Finite Difference\n",
    "def finite_diff(fnn,x,y):\n",
    "    fnn.feed(x,sigmoid)\n",
    "    w = fnn.layer_list[0].Weights\n",
    "    b = fnn.layer_list[0].bias\n",
    "    x = fnn.layer_list[0].x\n",
    "    bias_gradients = (quadratic(sigmoid(w.T @ x + (b+0.0001)),y) - quadratic(sigmoid(w.T @x + b),y))/0.0001\n",
    "    weight_gradient = []\n",
    "    for i in range(len(w)):\n",
    "        preturbed_w = w.copy()\n",
    "        preturbed_w[i] += 0.0001\n",
    "        weight_gradient.append((quadratic(sigmoid((preturbed_w.T @ x + b)),y) - quadratic(sigmoid(w.T @ x + b),y))/0.0001)\n",
    "    return weights_gradients,bias_gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Initialize Weights&Bias\n",
    "w = np.array([[-1,1],[1,-1]],dtype = 'float')\n",
    "b = np.array([2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<--Back Propagation-->\n",
      "Weights gradients:[array([[-0.03469004,  0.25      ],\n",
      "       [ 0.03469004, -0.25      ]])]\n",
      "Bias gradients:[array([ 0.03469004, -0.25      ])]\n",
      "\n",
      "\n",
      "<--Finite Difference-->\n",
      "Weights gradients:[array([[-0.03469004,  0.25      ],\n",
      "       [ 0.03469004, -0.25      ]])]\n",
      "Bias gradients:[ 0.0346884  -0.24999375]\n"
     ]
    }
   ],
   "source": [
    "f1 = FNN(2)\n",
    "f1.addLayer(2,2)\n",
    "f1.layer_list[0].setWeight(w)\n",
    "f1.layer_list[0].setBias(b)\n",
    "x = np.array([-1,1])\n",
    "y = np.array([0,1])\n",
    "weights_gradients,bias_gradients = back_propagation(f1,x,y)\n",
    "del f1\n",
    "print(\"<--Back Propagation-->\")\n",
    "print(\"Weights gradients:{}\".format(weights_gradients))\n",
    "print(\"Bias gradients:{}\".format(bias_gradients))\n",
    "f1 = FNN(2)\n",
    "f1.addLayer(2,2)\n",
    "f1.layer_list[0].setWeight(w)\n",
    "f1.layer_list[0].setBias(b)\n",
    "weights_gradients,bias_gradients = finite_diff(f1,x,y)\n",
    "print('\\n')\n",
    "print(\"<--Finite Difference-->\")\n",
    "print(\"Weights gradients:{}\".format(weights_gradients))\n",
    "print(\"Bias gradients:{}\".format(bias_gradients))\n",
    "del f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traning Ising "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fnn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Read train_data file\n",
    "url = 'Ising/'\n",
    "file = open(url+'train_data.txt').readlines()\n",
    "train_dataset = np.zeros([10000,100])\n",
    "i = 0 \n",
    "for line in file:\n",
    "    line = line.split()\n",
    "    for j in range(len(line)):\n",
    "        train_dataset[i][j] = int(line[j])\n",
    "    i+=1\n",
    "file = open(url+'train_label.txt').readlines()\n",
    "train_labelset = np.zeros([10000,1])\n",
    "i = 0\n",
    "for line in file:\n",
    "    line = line.split()\n",
    "    for j in range(len(line)):\n",
    "        train_labelset[i][j] = int(line[j])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Read Test file\n",
    "url = 'Ising/'\n",
    "file = open(url+'test_data.txt').readlines()\n",
    "test_dataset = np.zeros([10000,100])\n",
    "i = 0 \n",
    "for line in file:\n",
    "    line = line.split()\n",
    "    for j in range(len(line)):\n",
    "        test_dataset[i][j] = int(line[j])\n",
    "    i+=1\n",
    "file = open(url+'test_label.txt').readlines()\n",
    "test_labelset = np.zeros([10000,1])\n",
    "i = 0\n",
    "for line in file:\n",
    "    line = line.split()\n",
    "    for j in range(len(line)):\n",
    "        test_labelset[i][j] = int(line[j])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Initialize a 2-Layer Feedforward Network with n1 = 100, m1 = 100 & n2 = 100, m2 =1\n",
    "Ising_FNN = FNN(100)\n",
    "Ising_FNN.addLayer(100,100)\n",
    "Ising_FNN.addLayer(100,1)\n",
    "w_1 = np.zeros([100,100])\n",
    "w_2 = np.zeros([100,1])\n",
    "b_1 = np.zeros(100)\n",
    "b_2 = np.random.uniform(-0.01,0.01)\n",
    "for i in range(100):\n",
    "    w_2[i] = np.random.uniform(-0.01,0.01)\n",
    "    for j in range(100):\n",
    "        w_1[i,j] = np.random.uniform(-0.01,0.01)\n",
    "Ising_FNN.layer_list[0].setWeight(w_1)\n",
    "Ising_FNN.layer_list[0].setBias(b_1)\n",
    "Ising_FNN.layer_list[1].setWeight(w_2)\n",
    "Ising_FNN.layer_list[1].setBias(b_2)\n",
    "alpha = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Train Model\n",
    "Ising_FNN.train(alpha,train_dataset,train_labelset,dc_dz = dcross_dz, batches = 10000,epoches = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'match': 8698, 'fail': 1302})\n",
      "0.8698\n"
     ]
    }
   ],
   "source": [
    "### Check predictions against test file\n",
    "import collections\n",
    "accuracy = collections.Counter()\n",
    "accuracy['match'] = 0\n",
    "accuracy['fail'] = 0\n",
    "predict_z = []\n",
    "for  test_data,test_label in zip(test_dataset,test_labelset):\n",
    "    predict = Ising_FNN.predict(test_data,sigmoid)\n",
    "    predict_z.append(predict)\n",
    "    if(-0.5 <test_label - predict < 0.5):\n",
    "        accuracy['match'] += 1\n",
    "    else:\n",
    "        accuracy['fail'] += 1\n",
    "print(accuracy)\n",
    "print(accuracy['match']/len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Read test_betaJ file\n",
    "file = open(url+'test_betaJ.txt').readlines()\n",
    "test_betaJ = []\n",
    "i = 0\n",
    "for line in file:\n",
    "    line = line.split()\n",
    "    for j in range(len(line)):\n",
    "        test_betaJ.append(float(line[j]))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJalA/w9dpjczm2FRNgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### average out the predicted M value for given betaJ\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "mapping = {}\n",
    "print(len(test_betaJ))\n",
    "for betaJ,predict in zip(list(test_betaJ),list(predict_z)):\n",
    "    if betaJ not in mapping:\n",
    "        mapping[betaJ] = [float(predict)]\n",
    "    mapping[betaJ].append(float(predict))\n",
    "avg = []\n",
    "for betaJ in mapping.keys():\n",
    "    avg.append(statistics.mean(mapping[betaJ]))\n",
    "plt.scatter(mapping.keys(),avg) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
